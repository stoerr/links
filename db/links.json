[
  {
    "filepath": "2024/02-11/wizardzine.md",
    "category": [
      "Productivity",
      "Development"
    ],
    "title": "Wizard Zines",
    "description": "An entertaining set of tipps for programmers - with a surprising amount of useful nice little stuff you might not have heard about even as a seasoned SoftwareEngineer .",
    "url": "https://wizardzines.com/comics/",
    "text": "# Wizard Zines\n\nhttps://wizardzines.com/comics/ \n\nAn entertaining set of tipps for programmers - with a surprising amount of useful\nnice little stuff you might not have heard about even as a seasoned SoftwareEngineer ."
  },
  {
    "filepath": "2024/02-12/TheArtOfCodingACruelOptimism.md",
    "category": [
      "AI",
      "Coding",
      "Education",
      "Artificial Intelligence",
      "Code Generation"
    ],
    "url": "https://medium.com/electronic-life/the-art-of-coding-a-cruel-optimism-59fc52571e91",
    "title": "The Art of Coding - A Cruel Optimism?",
    "description": "An exploration into the potential and pitfalls of leveraging AI in the art of coding,particularly as a learning tool.",
    "text": "# The Art of Coding: A Cruel Optimism?\n\nhttps://medium.com/electronic-life/the-art-of-coding-a-cruel-optimism-59fc52571e91\n\n## Description\n\nAn exploration into the potential and pitfalls of leveraging AI in the art of coding, particularly as a learning tool.\n\n## Summary\n\n\"The Art of Coding: A Cruel Optimism?\" by Sunil Manghani narrates the creation and use of a custom GPT called *The Art of Coding*, designed as an AI assistant to teach coding. This tool targets individuals such as art professors interested in coding by offering explanations, feedback, and the ability to improve their Python programming skills. By leveraging the wealth of coding examples available, the AI demonstrates a natural proficiency in teaching coding, potentially revolutionizing software development by making it more accessible. The essay further discusses the broader implications of AI coding tools like GitHub Copilot and CodiumAI's AlphaCodium, pondering whether the ease and automation brought by such tools could undermine the quality and originality of coding.\n\nManghani draws on historical parallels such as Walter Benjamin's reflections on how photography changed art's nature and accessibility. Similarly, AI in coding could democratize the ability to program software, encouraging creativity and innovation outside traditional confines. However, the author also articulates concerns regarding 'cruel optimism,' a term by Lauren Berlant, highlighting the paradox where the pursuit of efficient coding through AI might hinder deep learning and understanding, leading to over-reliance and potential skill atrophy among programmers. The piece concludes by questioning if the initiative to make coding more accessible through AI assists in expanding creativity or if it inadvertently entrenches a dependency that could stifle the inherent artfulness and human insight in programming.\n\n// same thing as JSON:\n{\n    \"filename\": \"TheArtOfCodingACruelOptimism\",\n    \"category\": \"AI, Coding, Education, Artificial Intelligence, Code Generation\",\n    \"url\": \"https://medium.com/electronic-life/the-art-of-coding-a-cruel-optimism-59fc52571e91\"\n    \"title\": \"The Art of Coding: A Cruel Optimism?\"\n    \"description\": \"An exploration into the potential and pitfalls of leveraging AI in the art of coding, particularly as a learning tool.\"\n    \"summary\": \"The Art of Coding: A Cruel Optimism? by Sunil Manghani narrates the creation and use of a custom GPT called The Art of Coding, designed as an AI assistant to teach coding. This tool targets individuals such as art professors interested in coding by offering explanations, feedback, and the ability to improve their Python programming skills. By leveraging the wealth of coding examples available, the AI demonstrates a natural proficiency in teaching coding, potentially revolutionizing software development by making it more accessible. The essay further discusses the broader implications of AI coding tools like GitHub Copilot and CodiumAI's AlphaCodium, pondering whether the ease and automation brought by such tools could undermine the quality and originality of coding. Manghani draws on historical parallels such as Walter Benjamin's reflections on how photography changed art's nature and accessibility. Similarly, AI in coding could democratize the ability to program software, encouraging creativity and innovation outside traditional confines. However, the author also articulates concerns regarding 'cruel optimism,' a term by Lauren Berlant, highlighting the paradox where the pursuit of efficient coding through AI might hinder deep learning and understanding, leading to over-reliance and potential skill atrophy among programmers. The piece concludes by questioning if the initiative to make coding more accessible through AI assists in expanding creativity or if it inadvertently entrenches a dependency that could stifle the inherent artfulness and human insight in programming.\"\n}"
  },
  {
    "filepath": "2024/02-13/aem-links.md",
    "category": [
      "AEM",
      "Cheat Sheets",
      "Solutions"
    ],
    "url": "https://github.com/paulrohrbeck/aem-links",
    "title": "GitHub - paulrohrbeck/aem-links - Adobe Experience Manager links,cheat sheets and solutions to common problems.",
    "description": "Curated list of links,cheat sheets,and solutions to common problems for Adobe Experience Manager (AEM).",
    "text": "# GitHub - paulrohrbeck/aem-links: Adobe Experience Manager links, cheat sheets and solutions to common problems.\n\nhttps://github.com/paulrohrbeck/aem-links\n\n## Description\n\nCurated list of links, cheat sheets, and solutions to common problems for Adobe Experience Manager (AEM).\n\n## Summary\n\nThe GitHub repository \"paulrohrbeck/aem-links\" serves as a comprehensive resource hub for Adobe Experience Manager (AEM). It includes a meticulously compiled collection of links, cheat sheets, and solutions to tackle common problems encountered in AEM. Developed and maintained by Paul Rohrbeck, this repository aims to assist AEM developers, architects, and administrators by providing quick access to a wide range of valuable resources.\n\nThis repository covers various aspects of AEM, including component development, project planning, environment setup, and best practices. Among its contents, users can find detailed cheat sheets on topics such as HTL/Sightly, Core Components, Sling models, and Oak queries. It also provides links to external resources like official AEM documentation, community forums, and Adobe's technical blogs, which are essential for anyone working with Adobe's enterprise content management system.\n\nBeyond AEM-specific resources, \"paulrohrbeck/aem-links\" offers guidance on related technologies and tools like Dispatcher configuration, Sling Apache, and Maven project setup. By aggregating these resources in one accessible place, it streamlines the learning and development process for AEM practitioners, making it an invaluable reference for both newcomers and experienced professionals."
  },
  {
    "filepath": "2024/02-13/BedienungsanleitungSamsungGalaxyS7.md",
    "category": [
      "User Manual",
      "Instructions"
    ],
    "url": "https://downloadcenter.samsung.com/content/MC/201806/20180607135149892/DE/Ger/start_here.html",
    "title": "Benutzerhandbuch Samsung Galaxy S7 (SM-G930F)",
    "description": "User manual for Samsung Samsung Galaxy S7 (SM-G930F) in German.",
    "text": "# Benutzerhandbuch Samsung Galaxy S7 (SM-G930F)\n\nhttps://downloadcenter.samsung.com/content/MC/201806/20180607135149892/DE/Ger/start_here.html\n\n## Description\n\nUser manual for Samsung Samsung Galaxy S7 (SM-G930F) in German.\n\n## Summary\n\nThe webpage provides a user manual for Samsung device Samsung Galaxy S7 (SM-G930F) in German. It includes chapters on\nbasic information,\napplications, settings, and the appendix. Users can access further information by clicking on the provided links or\nicons. The page is designed for easy navigation and access to detailed instructions for Samsung device users. The manual\ncovers essential topics for users to maximize their experience with Samsung devices."
  },
  {
    "filepath": "2024/02-23/introducing-supermaven-code-completion.md",
    "category": [
      "Blog",
      "Code Completion Tool"
    ],
    "url": "https://supermaven.com/blog/introducing-supermaven",
    "title": "Supermaven",
    "description": "The fastest copilot. Supermaven uses a 300,000-token context window to provide the highest quality code completions.",
    "text": "# Supermaven\n\nhttps://supermaven.com/blog/introducing-supermaven\n\n## Description\n\nThe fastest copilot. Supermaven uses a 300,000-token context window to provide the highest quality code completions.\n\n## Summary\n\nSupermaven is a code completion tool that differentiates itself by offering a 300,000-token context window for more accurate suggestions. It addresses the limitations of other tools like Copilot by efficiently integrating information across a long context window, resulting in better completions even for complex and unique codebases.\n\nThe tool is designed to be fast and responsive, with custom infrastructure to handle large codebases while maintaining low latency. Supermaven also stands out by focusing on sequences of edits rather than just files, allowing it to quickly understand and assist with code refactoring tasks. Users can try Supermaven for themselves and provide feedback on its performance.\n\nOverall, Supermaven aims to provide a competitive alternative in the AI-powered code completion space, offering a unique approach to handling large context windows and delivering accurate suggestions based on user edits and repositories."
  },
  {
    "filepath": "2024/02-23/prompt-injection-via-unicode-tags.md",
    "category": [
      "Technology",
      "Social Media"
    ],
    "url": "https://twitter.com/rez0__/status/1758556246850896185",
    "title": "Invisible Prompt Injection via Unicode Tags",
    "description": "a way of unnoticedly injecting prompts into OpenAI's API",
    "text": "# Invisible Prompt Injection via Unicode Tags\n\nhttps://twitter.com/rez0__/status/1758556246850896185\n\n## Description\n\nIt's possible to inject prompts into OpenAI's API by using invisible unicode tags. This can be used to inject prompts into the API without the user noticing.\n\ndef convert_from_tag_chars(tagged_string):     return ''.join(chr(ord(ch) - 0xE0000) for ch in tagged_string if 0xE0061 <= ord(ch) <= 0xE007A)  tagged_input = input(\"Enter a string of tagged characters to convert to ASCII: \") ascii_output = convert_from_tag_chars(tagged_input) print(\"ASCII output:\", ascii_output)"
  },
  {
    "filepath": "2024/02-23/teaching-calculus-via-deepfakes.md",
    "category": [
      "Technology",
      "Social Media"
    ],
    "url": "https://twitter.com/nisten/status/1760745075712381018",
    "title": "JavaScript Disabled on Twitter",
    "description": "Teaching calculus with deep fakes",
    "text": "# Teaching calculus with deep fakes\n\nhttps://twitter.com/nisten/status/1760745075712381018"
  },
  {
    "filepath": "2024/03-05/create-a-custom-workflow-model-in-aem-with-a-full-code-coverage-unit-test.md",
    "category": [
      "Technology",
      "Coding",
      "AEM"
    ],
    "url": "https://medium.com/@jlanssie/create-a-custom-workflow-model-in-aem-with-a-full-code-coverage-unit-test-4178b2263b81",
    "title": "Create a custom Workflow Model in AEM and add full code coverage with a Unit Test",
    "description": "Set up a custom Workflow Model in AEM that can be used by an Author to create Workflows in AEM's Touch UI and ensure full code coverage with a Unit Test.",
    "text": "# Create a custom Workflow Model in AEM and add full code coverage with a Unit Test\n\nhttps://medium.com/@jlanssie/create-a-custom-workflow-model-in-aem-with-a-full-code-coverage-unit-test-4178b2263b81\n\n## Description\n\nSet up a custom Workflow Model in AEM that can be used by an Author to create Workflows in AEM's Touch UI and ensure full code coverage with a Unit Test.\n\n## Summary\n\nIn this detailed guide, the author explains how to create a custom Workflow Model in AEM using Java classes and annotations. The tutorial covers setting up the Workflow Model, fetching and adapting payload data, and creating a helper method to set property values.\n\nThe tutorial also includes a section on writing Unit Tests for the Workflow Model using AemContext and Mockito for mocking objects. It provides detailed steps to verify the workflow with and without arguments, manage sessions, and handle exceptions.\n\nThe final part of the tutorial guides you through setting up the workflow in AEM's Touch UI, launching the workflow, and verifying the results in CRX/DE. This comprehensive guide is a great resource for AEM developers looking to create custom Workflow Models with full code coverage Unit Tests."
  },
  {
    "filepath": "2024/03-05/create-custom-aem-menu-tools-with-granite-ui-shell.md",
    "category": [
      "AEM",
      "Customization",
      "UI Development"
    ],
    "url": "https://medium.com/@vsr061/create-custom-aem-menu-tools-with-granite-ui-shell-53c56e435f8a",
    "title": "Create Custom AEM Menu Tools with Granite UI Shell",
    "description": "Customize AEM with Custom Menu Tools",
    "text": "# Create Custom AEM Menu Tools with Granite UI Shell\n\nhttps://medium.com/@vsr061/create-custom-aem-menu-tools-with-granite-ui-shell-53c56e435f8a\n\n## Description\n\nCustomize AEM with Custom Menu Tools\n\n## Summary\n\nThe article discusses how to create custom menu tools in AEM using Granite UI Shell. It covers concepts like Sling Resource Merger and Granite UI to customize AEM. The author explains the process of overlaying AEM Tools nodes, creating custom nodes, and developing a landing page using Granite UI components. The tutorial provides insights into structuring the nodes, properties to add for menu items and tools, and the use of Granite Shell Page for rendering. The article is a helpful guide for developers looking to enhance and customize AEM menus with their own tools."
  },
  {
    "filepath": "2024/03-05/develop-front-end-components-with-aem-coral-ui.md",
    "category": [
      "AEM",
      "Front End Development",
      "Coral UI"
    ],
    "url": "https://medium.com/@vsr061/develop-front-end-components-with-aem-coral-ui-2da905096cce",
    "title": "Develop Front End Components with AEM Coral UI | by Viraj Rane | Medium",
    "description": "Coral UI is a library of touch-first web components,used to ease the work of a front end developer.",
    "text": "# Develop Front End Components with AEM Coral UI | by Viraj Rane | Medium\n\nhttps://medium.com/@vsr061/develop-front-end-components-with-aem-coral-ui-2da905096cce\n\n## Description\n\nCoral UI is a library of touch-first web components, used to ease the work of a front end developer.\n\n## Summary\n\nCoral UI provides simple and responsive components to maintain platform uniformity in AEM. The article discusses how to add custom components using Coral UI, like buttons and drop-downs, by leveraging client-side JS and integrating with AEM's existing structure.\n\nThe tutorial guides on adding buttons to the AEM Inbox action bar, explaining steps to create clientlibs, utilize Coral UI's library, and customize interactions for a seamless user experience. The use of Coral UI ensures consistency and eases the development process in AEM for front end components.\n\nViraj Rane, a Full Stack AEM Developer and Tech Enthusiast, shares insights on utilizing Coral UI for AEM front end development, emphasizing code management and component uniformity across the platform."
  },
  {
    "filepath": "2024/03-05/how-to-create-a-custom-tool-in-aem.md",
    "category": [
      "AEM",
      "Development"
    ],
    "url": "https://medium.com/@jlanssie/how-to-create-a-custom-tool-in-aem-78d14c1f66d5",
    "title": "How to create a custom Tool in AEM | by Jeremy Lanssiers | Medium",
    "description": "We set up a custom tool in AEM’s Tool section for creating site-wide functionalities.",
    "text": "# How to create a custom Tool in AEM\n\nhttps://medium.com/@jlanssie/how-to-create-a-custom-tool-in-aem-78d14c1f66d5\n\n## Description\n\nWe set up a custom tool in AEM’s Tool section. This is useful for creating site-wide functionalities that do not fit in a component.\n\n## Summary\n\nIn this guide, Jeremy Lanssiers explains how to create a custom tool in AEM by overlaying standard libraries and creating specific XML files. The process involves setting up the workspace filter, creating XML files for the tool entry, and designing a Granite UI dialog page for the tool. The tutorial also covers creating packages for client-side interactions and providing a step-by-step approach to creating an interactive AEM tool. This comprehensive walkthrough helps developers understand the process of creating custom tools in AEM."
  },
  {
    "filepath": "2024/03-20/reprompt-prompt-testing-made-simple.md",
    "category": [
      "AI",
      "Prompt Testing"
    ],
    "url": "https://reprompt.dev/",
    "title": "Reprompt - Prompt testing made simple",
    "description": "Reprompt helps developers test and optimize AI prompts quickly and efficiently.",
    "text": "# Reprompt - Prompt testing made simple\n\nhttps://reprompt.dev/\n\n## Description\n\nReprompt helps developers test and optimize AI prompts quickly and efficiently.\n\n## Summary\n\nReprompt is a tool that enables developers to save time testing their prompts, allowing them to generate multiple responses, analyze errors, and improve their LLM apps with ease. It offers features such as collaborative prompt testing, real-time trading, data-driven decision-making, and strong security standards. With Reprompt, developers can speed up their debugging process, analyze more data in less time, and have confidence in their prompt changes by comparing with previous versions. Sign up now to streamline your prompt testing process."
  },
  {
    "filepath": "2024/04-09/semgrep-autofix-llm.md",
    "category": [
      "Software Development",
      "LLM",
      "AI"
    ],
    "url": "https://choly.ca/post/semgrep-autofix-llm/",
    "title": "Semgrep: AutoFixes using LLMs",
    "description": "Explore how Semgrep can be used for AutoFixes with Large Language Models (LLMs).",
    "text": "# Semgrep: AutoFixes using LLMs\n\nhttps://choly.ca/post/semgrep-autofix-llm/\n\n## Description\n\nExplore how Semgrep can be used for AutoFixes with Large Language Models (LLMs).\n\n## Summary\n\nSemgrep is a powerful tool for searching code using Abstract Syntax Trees (AST), allowing users to define patterns to match against code. Not only does Semgrep search using patterns, but it also supports rewriting matches with the built-in autofix feature, making it a comprehensive tool for code analysis and correction.\n\nThe article delves into the concept of fixing Semgrep matches using a Large Language Model (LLM), where each match is fed into the LLM and replaced with the response. The author introduces \"semgrepx,\" a tool that serves as \"xargs for Semgrep,\" to facilitate rewriting matches using LLMs. By utilizing this approach, the author provides insights on improving the task by matching a larger expression than necessary and leveraging the LLM's features effectively.\n\nThe author also shares practical examples and notes on utilizing the autofix feature in Semgrep and experimenting with different Large Language Models for better performance in code corrections, such as Anthropic's Claude 3 Opus model. Overall, the article offers a unique perspective on combining Semgrep with LLMs for efficient auto-fixing in code analysis and refactoring processes."
  },
  {
    "filepath": "2024/04-09/your-ai-product-needs-evals.md",
    "category": [
      "AI",
      "LLM"
    ],
    "url": "https://hamel.dev/blog/posts/evals/",
    "title": "Your AI Product Needs Evals",
    "description": "How to construct domain-specific LLM evaluation systems.",
    "text": "# Your AI Product Needs Evals\n\nhttps://hamel.dev/blog/posts/evals/\n\n## Description\n\nHow to construct domain-specific LLM evaluation systems.\n\n## Summary\n\nThis blog post discusses the importance of having robust evaluation systems for AI products, specifically focusing on language models. The author shares insights and experiences from working with language models over the years, highlighting the common pitfalls in building AI products without proper evaluation systems.\n\nThe post discusses different levels of evaluation, from unit tests to human and model evaluations, and emphasizes the importance of rigorous evaluation for AI products. The author also provides practical tips and examples, such as creating test cases, logging traces, and automating evaluation processes.\n\nOverall, the post serves as a guide for building effective evaluation systems for AI products, showcasing how evaluation systems can drive rapid iteration and improvement in AI products."
  },
  {
    "filepath": "2024/04-11/building-files-to-prompt-entirely-using-claude-3-opus.md",
    "category": [
      "Technology",
      "AI",
      "Programming"
    ],
    "url": "https://simonw.substack.com/p/building-files-to-prompt-entirely",
    "title": "Building files-to-prompt entirely using Claude 3 Opus",
    "description": "Plus \"llm cmd\" and running OCR against PDFs and images directly in your browser",
    "text": "# Building files-to-prompt entirely using Claude 3 Opus\n\nhttps://simonw.substack.com/p/building-files-to-prompt-entirely\n\n## Description\n\nPlus \"llm cmd\" and running OCR against PDFs and images directly in your browser\n\n## Summary\n\nIn this newsletter, Simon Willison discusses building a tool called files-to-prompt using Claude 3 Opus. This tool allows piping several files at once into prompts for use with LLMs like Claude and GPT-4. Starting with a Click app cookiecutter template, Simon builds and refines the functionality of the tool, delegating code writing tasks to the Claude 3 Opus model. The newsletter also covers enhancements made to the tool, involving additional features and automated testing with LLMs. Additionally, there is a discussion on using ChatGPT Plus for similar automation tasks in file processing workflows."
  },
  {
    "filepath": "2024/04-11/test-gitaction-workflow.md",
    "category": [
      "GitHub",
      "Maven Central",
      "Java",
      "CI/CD"
    ],
    "url": "https://github.com/cometbid-sfi/test-gitaction-workflow",
    "title": "GitHub - cometbid-sfi/test-gitaction-workflow: Test github action workflow and publishing to maven central",
    "description": "Test github action workflow and publishing to maven central - cometbid-sfi/test-gitaction-workflow",
    "text": "# GitHub - cometbid-sfi/test-gitaction-workflow\n\nhttps://github.com/cometbid-sfi/test-gitaction-workflow\n\n## Description\n\nTest github action workflow and publishing to maven central\n\n## Summary\n\nThe webpage provides detailed instructions on how to publish artifacts to Maven Central using GitHub Actions. It covers setting up the project's pom.xml file, including required information like licenses, developers, SCM, adding plugins for source and javadoc attachments, signing artifacts with GPG keys, creating Sonatype JIRA account, setup steps, CI/CD workflow with GitHub Actions, and the deployment process. The content also emphasizes the importance of having a separate Maven profile for deployment, setting up GPG keys, and securely managing credentials. The approach aims to automate the build, sign, and deploy process to Maven Central repositories efficiently and securely."
  },
  {
    "filepath": "2024/04-17/typegear-ai.md",
    "category": [
      "AI",
      "Writing",
      "Productivity"
    ],
    "url": "https://typegear.ai/",
    "title": "typegear.ai – write smarter,not harder",
    "description": "AI-powered writing tool to enhance text editing and productivity.",
    "text": "# typegear.ai – write smarter, not harder\n\nhttps://typegear.ai/\n\n## Description\n\nAI-powered writing tool designed to enhance text editing and productivity.\n\n## Summary\n\ntypegear.ai is an AI-powered writing tool that allows users to effortlessly enhance their written text with ready-made presets. Whether you are a blogger, journalist, copywriter, student, or business professional, typegear.ai can help you improve your writing skills and simplify complex text. With features like spell-check, grammar-check, professional text editing, and personalized preset options, typegear.ai offers a seamless and user-friendly experience that can boost productivity and accuracy in writing tasks. With multi-language support and vast preset options, typegear.ai is a versatile tool for anyone looking to create high-quality written content efficiently."
  },
  {
    "filepath": "2024/04-18/shell-history-is-your-best-productivity-tool.md",
    "category": [
      "DevOps"
    ],
    "url": "https://martinheinz.dev/blog/110",
    "title": "Shell History Is Your Best Productivity Tool | Martin Heinz | Personal Website & Blog",
    "description": "If you work in shell/terminal often enough,then over time the history will become your personal knowledge vault,documentation and command reference.",
    "text": "# Shell History Is Your Best Productivity Tool | Martin Heinz | Personal Website & Blog\n\nhttps://martinheinz.dev/blog/110\n\n## Description\n\nIf you work in shell/terminal often enough, then over time the history will become your personal knowledge vault, documentation and command reference.\n\n## Summary\n\nThe article discusses various configuration options to optimize shell history in ZSH for improved productivity. It covers setting up history saving, ignoring certain commands, timestamps, fuzzy search, searching history efficiently using keybindings, synchronization across workstations, and more. By efficiently utilizing the shell history, users can turn it into a valuable tool for enhancing their productivity."
  },
  {
    "filepath": "2024/04-18/use-an-llm-to-automagically-generate-meaningful-git-commit-messages.md",
    "category": [
      "Technology",
      "Git"
    ],
    "url": "https://harper.blog/2024/03/11/use-an-llm-to-automagically-generate-meaningful-git-commit-messages/",
    "title": "Use an llm to automagically generate meaningful git commit messages | Harper Reed's Blog",
    "description": "Learn how to use AI to automatically generate meaningful Git commit messages using an llm CLI and git hooks.",
    "text": "# Use an llm to automagically generate meaningful git commit messages | Harper Reed's Blog\n\nhttps://harper.blog/2024/03/11/use-an-llm-to-automagically-generate-meaningful-git-commit-messages/\n\n## Description\n\nI've transformed my git commit process by using an AI to automatically generate meaningful messages. This setup involves a nifty integration of the llm CLI and git hooks, saving me time.\n\n## Summary\n\nThe blog post discusses using an llm CLI to generate meaningful Git commit messages automatically. By setting up git hooks and prompts, the author enables the AI to create informative commit messages based on the changes made. The post provides detailed steps on setting up the system prompt, creating hooks, and configuring Git to utilize the automated commit message generation. Overall, the implementation helps streamline the commit process and ensures consistent and descriptive messages for each commit made."
  },
  {
    "filepath": "2024/04-23/design-patterns-for-compound-ai-systems-conversational-ai-copilots-rag.md",
    "category": [
      "AI",
      "Conversational AI",
      "Compound AI Systems"
    ],
    "url": "https://medium.com/@raunak-jain/design-patterns-for-compound-ai-systems-copilot-rag-fa911c7a62e0",
    "title": "Design Patterns for Compound AI Systems (Conversational AI,CoPilots & RAG)",
    "description": "How to build configurable flows and compound AI systems using open source tools.",
    "text": "# Design Patterns for Compound AI Systems (Conversational AI, CoPilots & RAG)\n\nhttps://medium.com/@raunak-jain/design-patterns-for-compound-ai-systems-copilot-rag-fa911c7a62e0\n\n## Description\n\nHow to build configurable flows and compound AI systems using open source tools.\n\n## Summary\n\nResearchers at Berkeley discussed the shift towards Compound AI Systems, highlighting the evolution of complex pipelines and the importance of components working together. Common deployment patterns like RAG (retrieval and understanding is key), Multi-Agent Problem Solvers, Conversational AI, and CoPilots were explored. Compound AI systems are interconnected modules relying on each other to execute design patterns effectively.\n\nMulti-Agent designs offer benefits like separation of concerns, modularity, diversity, and reusability. The GPT Pilot project showcased layered communication among agents with complex prompt engineering techniques. The fine-tuning of agents is crucial for cost reduction and improved accuracy in CoPilot systems."
  },
  {
    "filepath": "2024/04-27/50-open-source-options-for-running-llms-locally.md",
    "category": [
      "Technology",
      "Machine Learning"
    ],
    "url": "https://medium.com/thedeephub/50-open-source-options-for-running-llms-locally-db1ec6f5a54f",
    "title": "50+ Open-Source Options for Running LLMs Locally | by Vince Lam | The Deep Hub | Mar,2024 | Medium",
    "description": "A comprehensive list of open-source options for running Large Language Models (LLMs) locally.",
    "text": "# 50+ Open-Source Options for Running LLMs Locally\n\nhttps://medium.com/thedeephub/50-open-source-options-for-running-llms-locally-db1ec6f5a54f\n\n## Description\n\nA comprehensive list of open-source options for running Large Language Models (LLMs) locally.\n\n## Summary\n\nIn this article, the author discusses the benefits of using locally hosted open weights LLMs, such as data privacy and cost savings. By utilizing free models and occasionally switching to GPT-4, significant savings were achieved. The post is divided into sections covering all-in-one desktop solutions, LLM inference via the CLI and backend API servers, and front-end UIs for connecting to LLM backends.\n\nVarious open-source tools and repositories for hosting open weights LLMs locally are highlighted, including desktop solutions like GPT4All and LM Studio alternatives like Jaan. CLI tools like llama.cpp and Ollama are discussed for local inference, along with front-end UIs such as Open WebUI and Lobe Chat for enhanced user interactions. The article provides insights into each tool's features and recommendations based on user experience and community engagement.\n\nOverall, the author recommends using tools like Ollama and Jan for local LLM inference, depending on user preferences. The article serves as a valuable resource for individuals looking to explore AI technologies locally and optimize their LLM usage for various tasks."
  },
  {
    "filepath": "2024/04-30/lm-studio-discover-download-and-run-local-llms.md",
    "category": [
      "Technology",
      "AI",
      "Software"
    ],
    "url": "https://lmstudio.ai/",
    "title": "LM Studio - Discover,download,and run local LLMs",
    "description": "LM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs).",
    "text": "# LM Studio - Discover, download, and run local LLMs\n\nhttps://lmstudio.ai/\n\n## Description\n\nLM Studio is an easy to use desktop app for experimenting with local and open-source Large Language Models (LLMs).\n\n## Summary\n\nLM Studio is a desktop application that allows users to experiment with local and open-source Large Language Models (LLMs). The app provides a simple yet powerful model configuration and inferencing user interface, enabling users to download and run any ggml-compatible model from Hugging Face. Additionally, LM Studio leverages the GPU when possible, enhancing the performance of model processing.\n\nThe website for LM Studio highlights its functionality, emphasizing the ease of discovering, downloading, and experimenting with local LLMs. With a focus on enabling users to work with LLMs in a seamless and efficient manner, LM Studio serves as a valuable tool for those interested in exploring and utilizing Large Language Models for various tasks. While JavaScript is required to run the app, LM Studio offers a convenient solution for individuals looking to engage with LLMs on their local machines."
  },
  {
    "filepath": "2024/04-30/microsoft-designer-stunning-designs-in-a-flash.md",
    "category": [
      "Design"
    ],
    "url": "https://designer.microsoft.com/",
    "title": "Microsoft Designer - Stunning designs in a flash",
    "description": "A graphic design app that helps you create professional quality designs for social media posts,invitations,digital postcards,and more.",
    "text": "# Microsoft Designer - Stunning designs in a flash\n\nhttps://designer.microsoft.com/\n\n## Description\n\nA graphic design app that helps you create professional quality designs for social media posts, invitations, digital\npostcards, and more.\n\n## Summary\n\nMicrosoft Designer offers a platform for creating stunning designs quickly and efficiently, catering to various needs\nsuch as social media posts, invitations, digital postcards,\nsocial media banners, graphics etc.. With this graphic design app, users can bring their creative ideas to life and\nproduce unique and professional-looking content. However, to utilize this app, enabling JavaScript is necessary to\nensure smooth functionality and optimal user experience."
  },
  {
    "filepath": "2024/05-14/building-files-to-prompt-entirely-using-claude-3-opus.md",
    "category": [
      "Technology",
      "Development"
    ],
    "url": "https://simonwillison.net/2024/Apr/8/files-to-prompt/",
    "title": "Building files-to-prompt entirely using Claude 3 Opus",
    "description": "Discover how Simon Willison built the files-to-prompt tool using Claude 3 Opus to streamline the development process.",
    "text": "# Building files-to-prompt entirely using Claude 3 Opus\n\nhttps://simonwillison.net/2024/Apr/8/files-to-prompt/\n\n## Description\n\nSimon Willison shares his experience of building the files-to-prompt tool using Claude 3 Opus to automate the development process.\n\n## Summary\n\nSimon Willison used a combination of files-to-prompt and LLM command-line tools to efficiently build and test the software. By leveraging Claude 3 Opus, he accelerated the development process and added features like .gitignore support. The tool's low stakes nature made it ideal for experimenting with this alternative development approach. Willison highlights the benefits and challenges of using LLMs for code generation and shares his successful experience in upgrading other projects using the same pattern."
  },
  {
    "filepath": "2024/05-14/cat-files-contents-script.md",
    "category": [
      "Code"
    ],
    "url": "https://ib.bsb.br/cat-files",
    "title": "cat files contents [script] — infoBAG",
    "description": "A script that extracts text from files in a specified directory,concatenates them,and saves the result.",
    "text": "# cat files contents [script] — infoBAG\n\nhttps://ib.bsb.br/cat-files\n\n## Description\n\nA script that extracts text from files in a specified directory, concatenates them, and saves the result.\n\n## Summary\n\nThe script starts by defining directories and supported file types. It then processes individual files based on their types, converting them to text if needed. Unsupported file types are processed using the 'cat' command. The script checks for textual output and appends the results to the final concatenated file. Once all files are processed, temporary files are cleaned up, and the process is completed successfully."
  },
  {
    "filepath": "2024/05-14/slop-is-the-new-name-for-unwanted-ai-generated-content.md",
    "category": [
      "AI",
      "Ethics"
    ],
    "url": "https://simonwillison.net/2024/May/8/slop/",
    "title": "Slop is the new name for unwanted AI-generated content",
    "description": "A discussion on the term \"slop\" as a new name for unwanted AI-generated content.",
    "text": "# Slop is the new name for unwanted AI-generated content\n\nhttps://simonwillison.net/2024/May/8/slop/\n\n## Description\n\nA discussion on the term \"slop\" as a new name for unwanted AI-generated content.\n\n## Summary\n\nThe author explores the concept of \"slop\" as a term for undesired content generated by AI tools. Drawing parallels to how \"spam\" became associated with unwanted emails, the term \"slop\" is proposed for unreviewed AI-generated content shared without consent. The author emphasizes personal AI ethics and the importance of not producing or sharing slop. The article also introduces the term \"slom\" for AI-generated spam, sparking a conversation around AI ethics and content generation practices."
  },
  {
    "filepath": "2024/05-15/making-large-language-models-work-for-you.md",
    "category": [
      "Blog"
    ],
    "url": "https://simonwillison.net/2023/Aug/27/wordcamp-llms/",
    "title": "Making Large Language Models work for you",
    "description": "Simon Willison's blog post about his keynote at WordCamp 2023 on Large Language Models.",
    "text": "# Making Large Language Models work for you\n\nhttps://simonwillison.net/2023/Aug/27/wordcamp-llms/\n\n## Description\n\nSimon Willison's blog post about his keynote at WordCamp 2023 on Large Language Models.\n\n## Summary\n\nSimon Willison gave an invited keynote at WordCamp 2023 in Maryland, focusing on Large Language Models. He provided a practical take on what Large Language Models are, how they work, and what can be accomplished with them. The post touches on various topics related to these models, such as their potential applications, the open source movement around them, and challenges like prompt injection. Willison emphasizes the importance of accessibility and control over technology, envisioning a future where more people can leverage computers effectively."
  },
  {
    "filepath": "2024/05-16/continue-dev.md",
    "category": [
      "Development",
      "AI"
    ],
    "url": "https://www.continue.dev/",
    "title": "Continue.Dev - Open-source IDE extensions for creating modular AI software development systems",
    "description": "Open-source IDE extensions for creating modular AI software development systems.",
    "text": "# Continue\n\nhttps://www.continue.dev/\n\n## Description\n\nOpen-source IDE extensions for creating modular AI software development systems, for VSCode and IntelliJ IDEA.\n\n## Summary\n\nContinue is a platform that helps developers stay in flow by removing barriers that block productivity when building software. Their open-source IDE extensions allow users to easily create their own modular AI software development system that can be improved over time. With features like code completion, referencing, and code rewriting from natural language, Continue aims to accelerate development and empower developers to become leaders in AI. The platform is designed to seamlessly integrate with various programming languages and contexts, making it a versatile tool for customizing and optimizing AI development. Additionally, Continue Enterprise offers enhanced capabilities for engineering teams to use and improve their AI software development systems, ultimately driving innovation and efficiency in the development process."
  },
  {
    "filepath": "2024/05-19/lobe-chat-personal-llm-productivity-tool-surpassing-the-chatgpt-ollama-user-experience.md",
    "category": [
      "Productivity",
      "AI",
      "Software"
    ],
    "url": "https://lobehub.com/",
    "title": "LobeHub - LobeChat: Personal LLM productivity tool,surpassing the ChatGPT / OLLaMA user experience",
    "description": "LobeChat brings you the best user experience of ChatGPT,OLLaMA,Gemini,Claude WebUI",
    "text": "# LobeHub - LobeChat: Personal LLM productivity tool, surpassing the ChatGPT / OLLaMA user experience\n\nhttps://lobehub.com/\n\n## Description\n\nLobeChat brings you the best user experience of ChatGPT, OLLaMA, Gemini, Claude WebUI\n\n## Summary\n\nLobeHub offers LobeChat, a personal LLM productivity tool that surpasses the user experience of ChatGPT and OLLaMA. LobeChat provides Engineer Assistant functionalities tailored to personal desires, aimed at boosting productivity and navigating the frontier of workflow. Users can build their AI assistant and professional team, enhancing creative ventures, writing projects, learning journeys, and career tasks. LobeChat also offers a variety of features such as text-to-image, text-to-speech, plugins, and multi-models, providing a comprehensive AI-powered experience for users. Additionally, upcoming features include Sora Video Generation support, group chat, enhanced search capabilities, and more modality support. LobeHub aims to empower users to achieve their AI dreams through innovative tools and features."
  },
  {
    "filepath": "2024/05-19/lobe-chat.md",
    "category": [
      "Open-Source",
      "AI",
      "Chat"
    ],
    "url": "https://github.com/lobehub/lobe-chat",
    "title": "GitHub - lobehub/lobe-chat: 🤯 Lobe Chat - an open-source,modern-design LLMs/AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Bedrock / Azure / Mistral / Perplexity ),Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT chat application.",
    "description": "🤯 Lobe Chat - an open-source,modern-design LLMs/AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Bedrock / Azure / Mistral / Perplexity ),Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT chat application.",
    "text": "# GitHub - lobehub/lobe-chat: 🤯 Lobe Chat\n\n[https://github.com/lobehub/lobe-chat](https://github.com/lobehub/lobe-chat)\n\n## Description\n\n🤯 Lobe Chat - an open-source, modern-design LLMs/AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Bedrock / Azure / Mistral / Perplexity ), Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT chat application.\n\n## Summary\n\nThe GitHub repository for Lobe Chat provides an open-source chat framework that integrates various AI providers such as OpenAI, Claude 3, Gemini, and more. It supports multi-modals like Vision and TTS, along with a plugin system for customization. The framework allows for easy deployment of private ChatGPT chat applications with just one click."
  },
  {
    "filepath": "2024/05-23/better-llm-prompting-using-the-panel-of-experts.md",
    "category": [
      "AI",
      "Machine Learning",
      "Natural Language Processing"
    ],
    "url": "https://sourcery.ai/blog/panel-of-experts/",
    "title": "Better LLM Prompting using the Panel-of-Experts",
    "description": "How roleplaying a panel discussion can improve LLM results",
    "text": "# Better LLM Prompting using the Panel-of-Experts\n\nhttps://sourcery.ai/blog/panel-of-experts/\n\n## Description\n\nHow roleplaying a panel discussion can improve LLM results\n\n## Summary\n\nThe blog post discusses how roleplaying a panel discussion can improve the performance of Large Language Models (LLMs) by using the Panel-of-Experts approach. It presents the limitations of Chain-of-Thought prompting and the transition to the Panel-of-Experts method to enhance the ability of LLMs to handle complex tasks. The author shares insights into the implementation of the Panel-of-Experts approach, including unit tests, modified prompts, and the impact on error rates. The post concludes with considerations on cost and the significant performance boost achieved with this approach."
  },
  {
    "filepath": "2024/05-26/h2ogpt-private-chat-with-local-gpt.md",
    "category": [
      "Chat",
      "AI"
    ],
    "url": "https://github.com/h2oai/h2ogpt?tab=readme-ov-file#macos-cpum1m2-with-full-document-qa-capability",
    "title": "GitHub - h2oai/h2ogpt Private chat with local GPT with document,images,video,etc.",
    "description": "Private chat with local GPT with document,images,video,etc. 100% private,Apache 2.0. Supports oLLaMa,Mixtral,llama.cpp,and more.",
    "text": "# GitHub - h2oai/h2ogpt: Private chat with local GPT with document, images, video, etc.\n\nhttps://github.com/h2oai/h2ogpt?tab=readme-ov-file#macos-cpum1m2-with-full-document-qa-capability\n\n## Description\n\nPrivate chat with local GPT with document, images, video, etc. 100% private, Apache 2.0. Supports oLLaMa, Mixtral, llama.cpp, and more.\n\n## Summary\n\nThe GitHub repository h2oai/h2ogpt offers a private chat solution with a local GPT supporting documents, images, videos, and more. It guarantees privacy and is licensed under Apache 2.0. The chat system supports various features like oLLaMa, Mixtral, llama.cpp, and provides a demo link for users to explore further. With this tool, users can engage in chat conversations using local GPT technology while maintaining data privacy.\n\n---"
  },
  {
    "filepath": "2024/05-26/transformers-js.md",
    "category": [
      "Machine Learning",
      "Web Development",
      "JavaScript"
    ],
    "url": "https://github.com/xenova/transformers.js",
    "title": "GitHub - xenova/transformers.js: State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser,with no need for a server!",
    "description": "State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser,with no need for a server!",
    "text": "# GitHub - xenova/transformers.js: State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser, with no need for a server!\n\n[GitHub Repository Link](https://github.com/xenova/transformers.js)\n\n## Description\n\nState-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser, with no need for a server!\n\n## Summary\n\nTransformers.js is designed to be functionally equivalent to Hugging Face's transformers python library, allowing users to run pretrained models in the browser. The library supports common tasks in text processing, computer vision, audio, and multimodal applications. It uses ONNX Runtime to run models in the browser, offering the ability to convert pretrained PyTorch, TensorFlow, or JAX models to ONNX format. The README provides guidance on installation, usage, examples, and contributions to the project."
  },
  {
    "filepath": "2024/05-26/webllm-home.md",
    "category": [
      "AI",
      "Machine Learning"
    ],
    "url": "https://webllm.mlc.ai/",
    "title": "WebLLM | Home",
    "description": "High-Performance In-Browser LLM Serving Engine.",
    "text": "# WebLLM | Home\n\nhttps://webllm.mlc.ai/\n\n## Description\n\nHigh-Performance In-Browser LLM Serving Engine.\n\n## Summary\n\nWebLLM is a project aimed at bringing diversity to the ecosystem of generative AI and LLMs by enabling the direct running of language models inside a browser. By doing so, the project offers cost reduction, personalization, and privacy protection benefits for client personal AI models. Users can select a model, enter inputs, and run it directly in the browser. The project leverages WebGPU technology and provides instructions for running different models efficiently. It also emphasizes the research purposes of the demo site and compliance with model licenses."
  },
  {
    "filepath": "2024/05-29/training-is-not-the-same-as-chatting.md",
    "category": [
      "Technology",
      "Machine Learning"
    ],
    "url": "https://simonwillison.net/2024/May/29/training-not-chatting",
    "title": "Training is not the same as chatting - ChatGPT and other LLMs don’t remember everything you say",
    "description": "Common misconception about LLMs like ChatGPT regarding how training works.",
    "text": "# Training is not the same as chatting: ChatGPT and other LLMs don’t remember everything you say\n\n[https://simonwillison.net/2024/May/29/training-not-chatting](https://simonwillison.net/2024/May/29/training-not-chatting)\n\n## Description\n\nCommon misconception about LLMs like ChatGPT involving how training works.\n\n## Summary\n\nThe article addresses the misconception that ChatGPT and similar tools remember and learn from everything you say, highlighting that these models are stateless functions that do not directly learn or memorize the conversations. It explains the process of model training and how these models work independently for each new conversation. The article also discusses features like memory in LLMs and the concerns related to data privacy and policy decisions based on inaccurate assumptions."
  },
  {
    "filepath": "2024/05-30/codegpt-intellij-ides-plugin-marketplace.md",
    "category": [
      "IntelliJ IDEs",
      "AI Coding Assistant"
    ],
    "url": "https://plugins.jetbrains.com/plugin/21056-codegpt",
    "title": "CodeGPT - IntelliJ IDEs Plugin | Marketplace",
    "description": "Introducing CodeGPT: Your Free,Open-Source AI Copilot for Coding.",
    "text": "# CodeGPT - IntelliJ IDEs Plugin | Marketplace\n\n[https://plugins.jetbrains.com/plugin/21056-codegpt](https://plugins.jetbrains.com/plugin/21056-codegpt)\n\n## Description\n\nIntroducing CodeGPT: Your Free, Open-Source AI Copilot for Coding.\n\n## Summary\n\nCodeGPT is an AI coding assistant that offers support throughout the software development process. It is a free and open-source tool designed to help developers with coding tasks. With CodeGPT, users can expect assistance and suggestions to enhance their coding experience, making it easier and more efficient. Whether you are a beginner or an experienced coder, CodeGPT aims to augment your capabilities and streamline your workflow."
  },
  {
    "filepath": "2024/05-30/introducing-github-copilot-extensions-unlocking-unlimited-possibilities-with-our-ecosystem-of-partners.md",
    "category": [
      "Product",
      "Engineering"
    ],
    "url": "https://github.blog/2024-05-21-introducing-github-copilot-extensions/",
    "title": "Introducing GitHub Copilot Extensions: Unlocking unlimited possibilities with our ecosystem of partners - The GitHub Blog",
    "description": "The world of Copilot is getting bigger,improving the developer experience by keeping developers in the flow longer and allowing them to do more in natural language.",
    "text": "# Introducing GitHub Copilot Extensions: Unlocking unlimited possibilities with our ecosystem of partners - The GitHub Blog\n\n[https://github.blog/2024-05-21-introducing-github-copilot-extensions/](https://github.blog/2024-05-21-introducing-github-copilot-extensions/)\n\n## Description\n\nThe world of Copilot is getting bigger, improving the developer experience by keeping developers in the flow longer and allowing them to do more in natural language.\n\n## Summary\n\nGitHub is introducing GitHub Copilot Extensions to bring the world’s knowledge into the most widely adopted AI developer tool. Through a growing partner ecosystem, Copilot Extensions enables developers to build and deploy to the cloud in their natural language with their preferred tools and services. With this new feature, developers can stay in the flow longer, uplevel their skills, and innovate faster. The initial partners for GitHub Copilot Extensions include DataStax, Docker, LaunchDarkly, Microsoft Azure, and more, making it easier for developers to access a variety of tools and services seamlessly within their workflow.\n\nCopilot Extensions aim to streamline the development process by integrating various tools directly into GitHub Copilot Chat, allowing developers to access documentation, monitor errors, interact with databases, deploy applications, and more—all within one interface. This integration is designed to minimize context-switching, maintain flow state, and accelerate software delivery. As this feature expands, developers will have access to even more tools and services from a growing number of partners to enhance their productivity and efficiency."
  },
  {
    "filepath": "2024/05-30/what-we-learned-from-a-year-of-building-with-llms-part-i.md",
    "category": [
      "AI & ML"
    ],
    "url": "https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i",
    "title": "What We Learned from a Year of Building with LLMs (Part I)",
    "description": "Insights and lessons learned from a year of building real-world applications with Large Language Models (LLMs).",
    "# What We Learned from a Year of Building with LLMs (Part I": "# What We Learned from a Year of Building with LLMs (Part I)",
    "[https": "//www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i)",
    "## Descriptio": "## Description",
    "Insights and lessons learned from a year of building real-world applications with Large Language Models (LLMs)": "Insights and lessons learned from a year of building real-world applications with Large Language Models (LLMs).",
    "## Summar": "## Summary",
    "It's an exciting time to build with large language models (LLMs), as they have become “good enough” for real-world applications. The pace of improvements in LLMs is driving significant investment in AI. This article shares crucial lessons and methodologies for developing products based on LLMs. The content is organized into three sections": "tactical,operational,and strategic,with this being the first part focusing on the tactical aspects. Key topics covered include prompting,structured inputs and outputs,information retrieval strategies,guarding against hallucinations,and simplifying annotation tasks for LLMs.",
    "text": ""
  },
  {
    "filepath": "2024/06-01/inversion-the-billionaire-thinking-skill-you-were-never-taught-in-school.md",
    "category": [
      "Personal Development",
      "Business",
      "Investing"
    ],
    "url": "https://www.mayooshin.com/inversion-charlie-munger-billionaire-thinking",
    "title": "Inversion - The Billionaire Thinking Skill You Were Never Taught in School.",
    "description": "Exploring the concept of inversion as a thinking skill,inspired by Charlie Munger,to make better decisions and solve problems effectively.",
    "text": "# Inversion: The Billionaire Thinking Skill You Were Never Taught in School.\n\n[https://www.mayooshin.com/inversion-charlie-munger-billionaire-thinking](https://www.mayooshin.com/inversion-charlie-munger-billionaire-thinking)\n\n## Description\n\nExploring the concept of inversion as a thinking skill, inspired by Charlie Munger, to make better decisions and solve problems effectively.\n\n## Summary\n\nThe article delves into the concept of inversion, inspired by billionaire investor Charlie Munger, as a powerful thinking skill. By considering the opposite of what one wants to achieve, individuals can proactively plan to avoid failures and make better decisions. The technique is highlighted as a key factor in the success of individuals like Munger and Warren Buffett.\n\nInversion, a counterintuitive way of problem-solving, is explained through examples and its origins from mathematician Carl Jacobi. By focusing on preventing negative outcomes, individuals can strategically plan to achieve their goals. The article emphasizes the importance of combining forward and backward thinking to unlock solutions to challenging problems and improve decision-making.\n\nPractical applications of the inversion technique are provided, showcasing how individuals can use it to approach everyday problems from a different perspective. By thinking about what they want to avoid, individuals can develop preventive solutions and enhance their problem-solving abilities. Overall, inversion is presented as a valuable tool for innovation and decision-making in various aspects of life."
  },
  {
    "filepath": "2024/06-07/from-gpt-4-to-agi.md",
    "category": [
      "AI",
      "ChatGPT"
    ],
    "url": "https://situational-awareness.ai/from-gpt-4-to-agi/",
    "title": "I. From GPT-4 to AGI - Counting the OOMs",
    "description": "AGI by 2027 is strikingly plausible. Exploring the trends in compute,algorithmic efficiencies,and \"unhobbling\" gains to predict future progress.",
    "text": "# I. From GPT-4 to AGI: Counting the OOMs\n\n[https://situational-awareness.ai/from-gpt-4-to-agi/](https://situational-awareness.ai/from-gpt-4-to-agi/)\n\n## Description\n\nAGI by 2027 is strikingly plausible. Exploring the trends in compute, algorithmic efficiencies, and \"unhobbling\" gains to predict future progress.\n\n## Summary\n\nAGI by 2027 is a realistic possibility, as evidenced by the rapid advancements from GPT-2 to GPT-4 in the last few years. The progress in deep learning has been extraordinary, with models now outperforming humans in various tasks. The article discusses the significant trends in effective compute scaling, algorithmic progress, and potential breakthroughs in removing limitations to achieve AGI. The key takeaway is that the next decade will witness a rapid scale-up in OOMs, leading to significant advancements in AI capabilities."
  },
  {
    "filepath": "2024/06-07/getting-started-with-openai-evals.md",
    "category": [
      "Evaluation",
      "OpenAI"
    ],
    "url": "https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals",
    "title": "Getting Started with OpenAI Evals - OpenAI Cookbook",
    "description": "Open-source examples and guides for building with the OpenAI API.",
    "text": "# Getting Started with OpenAI Evals - OpenAI Cookbook\n\n[https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals)\n\n## Description\n\nOpen-source examples and guides for building with the OpenAI API.\n\n## Summary\n\nThe OpenAI Evals framework consists of a framework to evaluate an LLM (large language model) or a system built on top of an LLM. It also includes an open-source registry of challenging evals. The guide covers the introduction to Evaluation and the OpenAI Evals library, building an Eval, running an Eval, different types of evals, the importance of evaluations, and OpenAI Eval templates. It also provides instructions on setting up and building an evaluation for OpenAI Evals framework. The tutorial includes examples and explanations on how different types of evaluations can be used and implemented effectively. Overall, this guide serves as a comprehensive resource for getting started with OpenAI Evals."
  },
  {
    "filepath": "2024/06-07/reusing-content-multi-site-manager-and-live-copy.md",
    "category": [
      "Reusing Content",
      "Multi Site Manager",
      "Live Copy"
    ],
    "url": "https://experienceleague.adobe.com/en/docs/experience-manager-cloud-service/content/sites/administering/reusing-content/msm/overview",
    "title": "Reusing Content - Multi Site Manager and Live Copy | Adobe Experience Manager",
    "description": "Get an introduction to reusing content with AEM's powerful Live Copies and the Multi Site Manager features.",
    "text": "# Reusing Content - Multi Site Manager and Live Copy | Adobe Experience Manager\n\n[https://experienceleague.adobe.com/en/docs/experience-manager-cloud-service/content/sites/administering/reusing-content/msm/overview](https://experienceleague.adobe.com/en/docs/experience-manager-cloud-service/content/sites/administering/reusing-content/msm/overview)\n\n## Description\n\nGet an introduction to reusing content with AEM's powerful Live Copies and the Multi Site Manager features.\n\n## Summary\n\nThe Multi Site Manager (MSM) in Adobe Experience Manager allows users to reuse the same site content in multiple locations using Live Copies. With MSM, content can be created once and reused in various areas of the same or different sites, maintaining live relationships between source content and its Live Copies for synchronization. The documentation provides an overview of reusing content with MSM, covering topics like creating and synchronizing Live Copies, Live Copy overview console, configuring Live Copy synchronization, MSM rollout conflicts, and best practices. MSM functionality can also be used for Assets and Content Fragments. Scenarios for using MSM include multinational applications, national offices to regional branches, and creating multiple versions of a specific sub-branch. Live Copies in MSM can be structured as shallow or deep, and can be composed of non-Live Copy pages or nested Live Copies, with options to detach Live Copies and suspend or cancel inheritance and synchronization. The documentation also includes standard steps for using MSM and customizing rollout configurations, as well as best practices for implementation."
  },
  {
    "filepath": "2024/06-09/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model.md",
    "category": [
      "Technology",
      "Data Science",
      "Machine Learning"
    ],
    "url": "https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8",
    "title": "6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model | by Youness Mansar | May,2024 | Towards Data Science",
    "description": "Exploring possible use cases of Phi-3-Vision,a small yet powerful MLLM that can be run locally with code examples.",
    "text": "# 6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model\n\n[https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8](https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8)\n\n## Description\n\nExploring possible use cases of Phi-3-Vision, a small yet powerful MLLM that can be run locally with code examples.\n\n## Summary\n\nMicrosoft recently released Phi-3, a powerful language model called Phi-3-Vision-128k-instruct. This 4B parameter model has achieved impressive results on public benchmarks. It can be utilized in various real-world scenarios such as Optical Character Recognition, Image Captioning, Table Parsing, Figure Understanding, Reading Comprehension on Scanned Documents, and Set-of-Mark Prompting. The post provides code examples to run the model locally and showcases examples for each of these use cases. It discusses the model's efficiency due to its compact size and its applications in tasks like document parsing, table structure understanding, and OCR."
  },
  {
    "filepath": "2024/06-10/100-free-mindmap-generator-everlearns.md",
    "category": [
      "Mind Mapping",
      "Productivity",
      "Education"
    ],
    "url": "https://everlearns.com/mindmap-generator",
    "title": "100% FREE Mindmap Generator | EverLearns",
    "description": "Create,organize,and visualize your ideas effortlessly with our mindmap generator tool.",
    "text": "# 100% FREE Mindmap Generator | EverLearns\n\n[https://everlearns.com/mindmap-generator](https://everlearns.com/mindmap-generator)\n\n## Description\n\nCreate, organize, and visualize your ideas effortlessly with our mindmap generator tool.\n\n## Summary\n\nThe webpage offers a mindmap generator tool designed to help users create, organize, and visualize their ideas with ease. It highlights the benefits of boosting productivity and streamlining brainstorming sessions. The tool is free to use and caters to content creators, educators, teachers, teaching assistants, tutors, homeschooling parents, and more. Additionally, the page promotes AI-powered course creation efficiency and provides a demo for users interested in enhancing their course creation process."
  },
  {
    "filepath": "2024/06-12/kleiner-himmlischer-kreislauf-entdecke-das-licht-in-dir-und-lass-es-kreisen.md",
    "category": [
      "Health",
      "Wellness",
      "Qigong"
    ],
    "url": "https://www.tanden-aikido.de/der-kleine-himmlische-kreislauf/",
    "title": "Kleiner Himmlischer Kreislauf - Entdecke das Licht in Dir und lass es kreisen! - Tanden Dojo Berlin",
    "description": "Der Kleine Himmlische Kreislauf oder Kleine Kosmische Kreislauf ist eine der bekanntesten Qigong-Übungen.",
    "text": "# Kleiner Himmlischer Kreislauf - Entdecke das Licht in Dir und lass es kreisen! - Tanden Dojo Berlin\n\n[https://www.tanden-aikido.de/der-kleine-himmlische-kreislauf/](https://www.tanden-aikido.de/der-kleine-himmlische-kreislauf/)\n\n## Description\n\nDer Kleine Himmlische Kreislauf oder Kleine Kosmische Kreislauf ist eine der bekanntesten Qigong-Übungen.\n\n## Summary\n\nDiese Webseite diskutiert den Kleinen Himmlischen Kreislauf, eine beliebte Qigong-Übung. Sie bietet Einblicke in das, was Sie wissen müssen, um mit dieser Übung zu beginnen."
  }
]