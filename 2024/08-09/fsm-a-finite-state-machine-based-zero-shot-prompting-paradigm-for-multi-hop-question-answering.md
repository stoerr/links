---
filename: fsm-a-finite-state-machine-based-zero-shot-prompting-paradigm-for-multi-hop-question-answering
category: Machine Learning, Natural Language Processing
url: https://arxiv.org/html/2407.02964v1
title: FSM - A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering
description: This paper introduces a zero-shot prompting paradigm called Finite State Machine (FSM) for improving Multi-hop Question Answering (MHQA) tasks.
---
# FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering

[https://arxiv.org/html/2407.02964v1](https://arxiv.org/html/2407.02964v1)

## Description

This paper introduces a zero-shot prompting paradigm called Finite State Machine (FSM) for improving Multi-hop Question Answering (MHQA) tasks.

## Summary

The paper discusses the challenges faced by Large Language Models (LLMs) in addressing Multi-hop Question Answering (MHQA) tasks, noting issues like hallucination, error propagation, and limited context length. To tackle these challenges, the authors propose the FSM method, which decomposes questions into manageable, iterative sub-questions, improving both the reasoning capabilities and trustworthiness of the model. Experiments reveal that FSM notably excels in more complex datasets, particularly Musique, demonstrating enhanced accuracy and mitigation of hallucination effects.

The methodology is structured in stages; initially focusing on addressing sub-questions, followed by synthesizing the responses into a coherent answer. The paper provides comparisons with existing methods like Chain-of-Thought (COT) prompting, showcasing that FSM not only improves reasoning accuracy but also enforces a clearer output format, thereby reducing errors in answer interpretation. The results illustrate significant benefits of FSM in complex reasoning tasks, confirming its potential as a robust tool for enhancing LLM performance in MHQA scenarios.
